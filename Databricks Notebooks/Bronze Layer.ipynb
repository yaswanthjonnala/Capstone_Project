{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5d99cff-2f69-4d39-8b8e-966142250022",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**BRONZE LAYER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b5eb99d-c545-4060-962b-698c1aefe9e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DATA INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23b45105-75a6-40a3-8e7f-448e0b6f7d32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Bronze Layer: Raw Data Ingestion\n",
    "# Purpose:\n",
    "# - Load raw CSV files into Spark\n",
    "# - Apply explicit schemas\n",
    "# - Validate identifiers and basic data sanity\n",
    "# - No cleaning or transforming of data at this stage\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    StringType, IntegerType, DoubleType\n",
    ")\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebf0330c-c0ea-43a0-9372-9f1acf686641",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# These paths point to the raw datasets stored in Databricks Volumes.\n",
    "SCHOOL_MASTER_PATH = \"/Volumes/workspace/default/capstone/school_master.csv\"\n",
    "ENROLLMENT_PATH    = \"/Volumes/workspace/default/capstone/student_enrollment.csv\"\n",
    "PERFORMANCE_PATH   = \"/Volumes/workspace/default/capstone/student_performance.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a37118c8-77fa-4449-9538-068d339e7f99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# School master reference data schema\n",
    "school_master_schema = StructType([\n",
    "    StructField(\"school_id\", StringType(), False),\n",
    "    StructField(\"school_name\", StringType(), False),\n",
    "    StructField(\"region\", StringType(), False),\n",
    "    StructField(\"district\", StringType(), False),\n",
    "    StructField(\"school_type\", StringType(), False),\n",
    "    StructField(\"capacity\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "# Enrollment fact data schema\n",
    "enrollment_schema = StructType([\n",
    "    StructField(\"school_id\", StringType(), True),\n",
    "    StructField(\"academic_year\", IntegerType(), True),\n",
    "    StructField(\"grade_level\", DoubleType(), True), \n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"student_count\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Student performance fact data schema\n",
    "performance_schema = StructType([\n",
    "    StructField(\"school_id\", StringType(), False),\n",
    "    StructField(\"academic_year\", IntegerType(), False),\n",
    "    StructField(\"grade_level\", IntegerType(), True),\n",
    "    StructField(\"average_score\", DoubleType(), True),\n",
    "    StructField(\"attendance_percentage\", DoubleType(), True),\n",
    "    StructField(\"dropout_risk_flag\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2296859f-3d03-406e-9555-1c1efe8ad4f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load school master data\n",
    "df_school_master = (\n",
    "    spark.read\n",
    "         .format(\"csv\")\n",
    "         .option(\"header\", \"true\")\n",
    "         .schema(school_master_schema)\n",
    "         .load(SCHOOL_MASTER_PATH)\n",
    ")\n",
    "\n",
    "# Load student enrollment data\n",
    "df_enrollment = (\n",
    "    spark.read\n",
    "         .format(\"csv\")\n",
    "         .option(\"header\", \"true\")\n",
    "         .schema(enrollment_schema)\n",
    "         .load(ENROLLMENT_PATH)\n",
    ")\n",
    "\n",
    "# Load student performance data\n",
    "df_performance = (\n",
    "    spark.read\n",
    "         .format(\"csv\")\n",
    "         .option(\"header\", \"true\")\n",
    "         .schema(performance_schema)\n",
    "         .load(PERFORMANCE_PATH)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "024c021c-5d22-482b-9888-59a68ea4f19d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save Bronze tables as Delta\n",
    "df_school_master.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"bronze_school_master\")\n",
    "\n",
    "df_enrollment.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"bronze_student_enrollment\")\n",
    "\n",
    "df_performance.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"bronze_student_performance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea74f682-c2c7-48b1-b69f-cb3b990186f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "School Master Records: 120\nEnrollment Records: 7000\nPerformance Records: 7000\n"
     ]
    }
   ],
   "source": [
    "# Row count checks help catch empty or corrupted files early\n",
    "print(\"School Master Records:\", df_school_master.count())\n",
    "print(\"Enrollment Records:\", df_enrollment.count())\n",
    "print(\"Performance Records:\", df_performance.count())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze Layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}